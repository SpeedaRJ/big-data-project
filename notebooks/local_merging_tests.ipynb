{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"../data/parking_tickets/parquet/filtered/2017_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(\"../data/additional_data/weather/weather_NYC_2013_2024_processed.csv\", sep=\";\")\n",
    "ms_data = pd.read_csv(\"../data/additional_data/schools/middle_schools_NYC_2021_processed.csv\")\n",
    "hs_data = pd.read_csv(\"../data/additional_data/schools/high_schools_NYC_2021_processed.csv\")\n",
    "li_data = pd.read_csv(\"../data/additional_data/landmarks/landmarks_NYC_individual_processed.csv\")\n",
    "ls_data = pd.read_csv(\"../data/additional_data/landmarks/landmarks_NYC_scenic_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[\"datetime\"] = pd.to_datetime(weather_data[\"datetime\"]).astype(np.int64) // 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtree.index import Index\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from haversine import haversine\n",
    "\n",
    "\n",
    "def get_nearest_location(idx, lat, lang):\n",
    "    hit = list(idx.nearest((lat, lang, lat, lang), 1, objects=True))[0].object\n",
    "    return (hit[\"name\"], haversine((lat, lang), (hit[\"lat\"], hit[\"long\"])))\n",
    "\n",
    "\n",
    "def computational_wrapper(row, lat_i, long_i, idx):\n",
    "    return get_nearest_location(idx, row[lat_i], row[long_i])\n",
    "\n",
    "\n",
    "def process_merge(data, augment_data, new_name, distance_name, name=\"name\", save_location=None):\n",
    "    if os.path.exists(save_location):\n",
    "        return pd.read_parquet(save_location)\n",
    "    idx = Index()\n",
    "    for i, row in tqdm(\n",
    "        enumerate(augment_data.iterrows()),\n",
    "        desc=\"Builing location index\",\n",
    "        total=augment_data.shape[0],\n",
    "    ):\n",
    "        row = row[1]\n",
    "        idx.insert(\n",
    "            i,\n",
    "            (row[\"Latitude\"], row[\"Longitude\"], row[\"Latitude\"], row[\"Longitude\"]),\n",
    "            obj={\"name\": row[name], \"lat\": row[\"Latitude\"], \"long\": row[\"Longitude\"]},\n",
    "        )\n",
    "\n",
    "    lat_i = data.columns.tolist().index(\"Latitude\") + 1\n",
    "    long_i = data.columns.tolist().index(\"Longitude\") + 1\n",
    "    res = []\n",
    "\n",
    "    for row in tqdm(\n",
    "        data.itertuples(), total=data.shape[0], desc=\"Generating reference dataframe\"\n",
    "    ):\n",
    "        res.append(computational_wrapper(row, lat_i, long_i, idx))\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        res,\n",
    "        columns=[new_name, distance_name],\n",
    "        index=data.index,\n",
    "    )\n",
    "\n",
    "    data = data.merge(res, how=\"left\", left_index=True, right_index=True)\n",
    "    data.to_parquet(\n",
    "        save_location\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.8 s\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(\"../data/augmented_data/tickets_weather_2017.parquet\"):\n",
    "    data_w_weather = pd.read_parquet(\"../data/augmented_data/tickets_weather_2017.parquet\")\n",
    "else:\n",
    "    data_w_weather = data.merge(weather_data, how=\"left\", left_on=\"Issue Date\", right_on=\"datetime\")\n",
    "    data_w_weather.to_parquet(\"../data/augmented_data/tickets_weather_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 47)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Builing location index: 100%|██████████| 472/472 [00:00<00:00, 9252.80it/s]\n",
      "Generating reference dataframe: 100%|██████████| 7256771/7256771 [13:13<00:00, 9145.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min 42s\n",
      "Wall time: 13min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms = process_merge(data_w_weather, ms_data, \"Closest Middle School\", \"Distance to CMS\", \"name\", \"../data/augmented_data/tickets_w_ms_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 49)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_w_ms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Builing location index: 100%|██████████| 442/442 [00:00<00:00, 9581.33it/s]\n",
      "Generating reference dataframe: 100%|██████████| 7256771/7256771 [15:08<00:00, 7984.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15min 38s\n",
      "Wall time: 15min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms_hs = process_merge(data_w_w_ms, hs_data, \"Closest High School\", \"Distance to CHS\", \"school_name\", \"../data/augmented_data/tickets_w_ms_hs_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 51)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_w_ms_hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Builing location index: 100%|██████████| 1531/1531 [00:00<00:00, 8590.48it/s]\n",
      "Generating reference dataframe: 100%|██████████| 7256771/7256771 [12:45<00:00, 9476.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min 17s\n",
      "Wall time: 13min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms_hs_li = process_merge(data_w_w_ms_hs, li_data, \"Closest Individual Landmark\", \"Distance to CIL\", \"LPC_NAME\", \"../data/augmented_data/tickets_w_ms_hs_li_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 53)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_w_ms_hs_li.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Builing location index: 100%|██████████| 11/11 [00:00<00:00, 5499.74it/s]\n",
      "Generating reference dataframe: 100%|██████████| 7256771/7256771 [07:02<00:00, 17187.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 34s\n",
      "Wall time: 7min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms_hs_li_ls = process_merge(data_w_w_ms_hs_li, ls_data, \"Closest Scenic Landmark\", \"Distance to CIS\", \"SCEN_LM_NA\", \"../data/augmented_data/tickets_w_ms_hs_li_ls_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 55)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_w_ms_hs_li_ls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_locations(idx, lat, lang, n):\n",
    "    return [\n",
    "        item.object\n",
    "        for item in list(idx.nearest((lat, lang, lat, lang), n, objects=True))\n",
    "    ]\n",
    "\n",
    "\n",
    "def computational_wrapper(row, lat_i, long_i, idx, time_i, n=1):\n",
    "    locations = pd.DataFrame(get_nearest_locations(idx, row[lat_i], row[long_i], n))\n",
    "    locations = locations[\n",
    "        (locations[\"active_from\"] <= row[time_i])\n",
    "        & (locations[\"active_to\"] >= row[time_i])\n",
    "    ]\n",
    "    if locations.empty:\n",
    "        return computational_wrapper(row, lat_i, long_i, idx, time_i, n * 2)\n",
    "    return (\n",
    "        locations.iloc[0][\"name\"],\n",
    "        locations.iloc[0][\"industry\"],\n",
    "        haversine(\n",
    "            (row[lat_i], row[long_i]),\n",
    "            (locations.iloc[0][\"lat\"], locations.iloc[0][\"long\"]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def process_merge_2(\n",
    "    data, augment_data, new_name, distance_name, name=\"name\", save_location=None\n",
    "):\n",
    "    if os.path.exists(save_location):\n",
    "        return pd.read_parquet(save_location)\n",
    "    idx = Index()\n",
    "    for i, row in tqdm(enumerate(augment_data.iterrows()), total=augment_data.shape[0]):\n",
    "        row = row[1]\n",
    "        idx.insert(\n",
    "            i,\n",
    "            (row[\"Latitude\"], row[\"Longitude\"], row[\"Latitude\"], row[\"Longitude\"]),\n",
    "            obj={\n",
    "                \"name\": row[name],\n",
    "                \"industry\": row[\"Industry\"],\n",
    "                \"lat\": row[\"Latitude\"],\n",
    "                \"long\": row[\"Longitude\"],\n",
    "                \"active_from\": pd.Timestamp(\n",
    "                    row[\"License Creation Date\"], unit=\"ms\"\n",
    "                ).timestamp()\n",
    "                * 1000,\n",
    "                \"active_to\": pd.Timestamp(\n",
    "                    row[\"License Expiration Date\"], unit=\"ms\"\n",
    "                ).timestamp()\n",
    "                * 1000,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    lat_i = data.columns.tolist().index(\"Latitude\") + 1\n",
    "    long_i = data.columns.tolist().index(\"Longitude\") + 1\n",
    "    time_i = data.columns.tolist().index(\"Issue Date\") + 1\n",
    "    res = []\n",
    "\n",
    "    for row in tqdm(\n",
    "        data.itertuples(), total=data.shape[0], desc=\"Generating reference dataframe\"\n",
    "    ):\n",
    "        res.append(computational_wrapper(row, lat_i, long_i, idx, time_i))\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        res,\n",
    "        columns=[new_name, \"Industry of CB\", distance_name],\n",
    "        index=data.index,\n",
    "    )\n",
    "\n",
    "    data = data.merge(res, how=\"left\", left_index=True, right_index=True)\n",
    "    data.to_parquet(\n",
    "        save_location\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_data = pd.read_csv(\"../data/additional_data/businesses/businesses_NYC_2023_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172332/172332 [00:26<00:00, 6406.65it/s]\n",
      "Generating reference dataframe: 100%|██████████| 7256771/7256771 [3:44:54<00:00, 537.74it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3h 46min 18s\n",
      "Wall time: 3h 46min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_ms_hs_li_ls_b= process_merge_2(data_w_w_ms_hs_li_ls, b_data, \"Closest Business\", \"Distance to CB\", \"Business Name\", \"../data/augmented_data/tickets_w_ms_hs_li_ls_b_2017.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7256771, 58)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_ms_hs_li_ls_b.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
