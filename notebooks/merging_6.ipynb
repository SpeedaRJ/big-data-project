{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "year = 2024\n",
    "\n",
    "os.chdir(\"../data_scripts/\")\n",
    "\n",
    "from to_hdf5 import read_hdf5, save_to_hdf5\n",
    "\n",
    "os.chdir(\"../notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = pd.read_parquet(\"/home/rjutr/big-data-project/data/parking_tickets/parquet/filtered/2024_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_to_hdf5(tmp, \"/home/rjutr/big-data-project/data/parking_tickets/hdf5/filtered\", \"2024_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6984398, 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_hdf5(f\"../data/parking_tickets/hdf5/filtered/{year}_filtered.h5\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(\"../data/additional_data/weather/weather_NYC_2013_2024_processed.csv\", sep=\";\")\n",
    "weather_data[\"datetime\"] = pd.to_datetime(weather_data[\"datetime\"]).astype(np.int64) // 10**6\n",
    "\n",
    "ms_data = pd.read_csv(\"../data/additional_data/schools/middle_schools_NYC_2021_processed.csv\")\n",
    "hs_data = pd.read_csv(\"../data/additional_data/schools/high_schools_NYC_2021_processed.csv\")\n",
    "li_data = pd.read_csv(\"../data/additional_data/landmarks/landmarks_NYC_individual_processed.csv\")\n",
    "ls_data = pd.read_csv(\"../data/additional_data/landmarks/landmarks_NYC_scenic_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def process_type(type):\n",
    "    if type == np.int64 or type == np.int32:\n",
    "        return \"<i8\"\n",
    "    if type == np.dtype(\"O\") or type == \"string\":\n",
    "        return h5py.string_dtype(encoding=\"utf-8\")\n",
    "    if type == np.float64:\n",
    "        return \"float\"\n",
    "    raise ValueError(f\"Unknown type {type}\")\n",
    "\n",
    "def save_to_hdf5_test(data_processed, dropoff, filename):\n",
    "    data_types = [\n",
    "        (name, process_type(type)) for name, type in data_processed.dtypes.items()\n",
    "    ]\n",
    "    array = np.empty(len(data_processed), dtype=data_types)\n",
    "    for i, column in enumerate(data_processed.columns):\n",
    "        array[column] = data_processed[column]\n",
    "    print(array)\n",
    "    print(data_types)\n",
    "    # with h5py.File(os.path.join(dropoff, f\"{filename}.h5\"), \"w\") as h5df:\n",
    "    #     h5df.create_dataset(\"data\", data=array, compression=\"gzip\", compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rtree.index import Index\n",
    "from tqdm import tqdm\n",
    "from haversine import haversine\n",
    "\n",
    "\n",
    "def get_nearest_location(idx, lat, lang):\n",
    "    hit = list(idx.nearest((lat, lang, lat, lang), 1, objects=True))[0].object\n",
    "    return (hit[\"name\"], haversine((lat, lang), (hit[\"lat\"], hit[\"long\"])))\n",
    "\n",
    "\n",
    "def computational_wrapper(row, lat_i, long_i, idx):\n",
    "    return get_nearest_location(idx, row[lat_i], row[long_i])\n",
    "\n",
    "\n",
    "def process_merge(\n",
    "    data, augment_data, new_name, distance_name, name=\"name\", save_location=None\n",
    "):\n",
    "    if os.path.exists(save_location):\n",
    "        return read_hdf5(save_location)\n",
    "    idx = Index()\n",
    "    for i, row in tqdm(\n",
    "        enumerate(augment_data.iterrows()),\n",
    "        desc=\"Builing location index\",\n",
    "        total=augment_data.shape[0],\n",
    "    ):\n",
    "        row = row[1]\n",
    "        idx.insert(\n",
    "            i,\n",
    "            (row[\"Latitude\"], row[\"Longitude\"], row[\"Latitude\"], row[\"Longitude\"]),\n",
    "            obj={\"name\": row[name], \"lat\": row[\"Latitude\"], \"long\": row[\"Longitude\"]},\n",
    "        )\n",
    "\n",
    "    lat_i = data.columns.tolist().index(\"Latitude\") + 1\n",
    "    long_i = data.columns.tolist().index(\"Longitude\") + 1\n",
    "    res = []\n",
    "\n",
    "    for row in tqdm(\n",
    "        data.itertuples(), total=data.shape[0], desc=\"Generating reference dataframe\"\n",
    "    ):\n",
    "        res.append(computational_wrapper(row, lat_i, long_i, idx))\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        res,\n",
    "        columns=[new_name, distance_name],\n",
    "        index=data.index,\n",
    "    )\n",
    "\n",
    "    data = data.merge(res, how=\"left\", left_index=True, right_index=True)\n",
    "    file_loc_split = save_location.split(\"/\")\n",
    "    save_to_hdf5(data, \"/\".join(file_loc_split[:-1]), file_loc_split[-1].split(\".\")[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1252994175, b'MBH9245', b'PA', b'PAS', 1688774400000, 40, b'SDN', b'KIA', b'M', 12690, 41700, 61090, 20231231, 108, 108, 968, 272834, b'0968', b'0000', b'1150P', b'Queens', b'F', b'39-41', b'60TH ST', b'', 0, 408, b'D', b'', b'BBBBBBB', b'ALL', b'ALL', b'WHITE',    0, 0, b'', b'', 40.7302249, -73.8594073, 1.6887744e+12, 30.7, 23.9, 25.9, 'Partially cloudy', 80.1, 17.8, 15.4)\n",
      " (1326049732, b'KXG5820', b'NY', b'PAS', 1688342400000, 14, b'SDN', b'HONDA', b'P', 59590,  9440,     0, 20240428, 109, 109, 109, 975295, b'0109', b'0000', b'0834P', b'Queens', b'', b'', b'PRINCE STREET', b'40 ROAD', 0, 408, b'E2', b'', b'BBBBBBB', b'ALL', b'ALL', b'GREY', 2007, 0, b'', b'', 40.7586145, -73.8316913, 1.6883424e+12, 31.1, 23.3, 26.9, 'Rain, Partially cloudy', 71.3, 14.7, 15.7)\n",
      " (1377539143, b'KSF8886', b'NY', b'PAS', 1688601600000, 46, b'DELV', b'JEEP', b'P', 24690, 36670, 36690, 20231017,  32,  32,  32, 972348, b'0032', b'0000', b'0940P', b'Manhattan', b'F', b'703', b'LENOX AVE', b'', 0, 408, b'E2', b'', b'BBBBBBB', b'ALL', b'ALL', b'GRAY', 2021, 0, b'', b'', 40.8209991, -73.9360464, 1.6886016e+12, 31.2, 23.9, 27.1, 'Rain', 70.8, 17.5, 16. )\n",
      " ...\n",
      " (9133935191, b'MAL1K', b'NY', b'OMT', 1716854400000, 46, b'SUBN', b'TOYOT', b'T', 22680, 21980, 22030, 20240930,  60,  60,  60, 366548, b'T302', b'I', b'0831P', b'Brooklyn', b'F', b'505', b'Brighton Beach Ave', b'', 0, 408, b'F1', b'', b'YYYYYYY', b'', b'', b'GY', 2016, 0, b'CC1', b'46A-Double Parking (Non-COM)', 40.5766058, -73.9658544, 1.7168544e+12, 26.7, 18.9, 22.5, 'Partially cloudy', 64.1, 35.7, 15.9)\n",
      " (9133935208, b'T720318C', b'NY', b'OMT', 1716854400000, 46, b'4DSD', b'TOYOT', b'T', 22680, 21980, 22030, 20241130,  60,  60,  60, 366548, b'T302', b'I', b'0832P', b'Brooklyn', b'F', b'504', b'Brighton Beach Ave', b'', 0, 408, b'F1', b'', b'YYYYYYY', b'', b'', b'GY', 2016, 0, b'CC1', b'46A-Double Parking (Non-COM)', 40.5766058, -73.9658544, 1.7168544e+12, 26.7, 18.9, 22.5, 'Partially cloudy', 64.1, 35.7, 15.9)\n",
      " (9133935210, b'LBJ4302', b'NY', b'PAS', 1716854400000, 46, b'SUBN', b'HONDA', b'T', 28830, 14280, 14330, 20250629,  70,  70,  70, 366548, b'T302', b'I', b'0908P', b'Brooklyn', b'O', b'1790', b'Coney Island Ave', b'', 0, 408, b'F1', b'', b'YYYYYYY', b'', b'', b'BK', 2021, 0, b'CC1', b'46A-Double Parking (Non-COM)', 40.6126362, -73.9703973, 1.7168544e+12, 26.7, 18.9, 22.5, 'Partially cloudy', 64.1, 35.7, 15.9)]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"../data/augmented_data/tickets_weather_{year}.h5\"):\n",
    "    data_w_weather = read_hdf5(f\"../data/augmented_data/tickets_weather_{year}.h5\")\n",
    "else:\n",
    "    data_w_weather = data.merge(weather_data, how=\"left\", left_on=\"Issue Date\", right_on=\"datetime\")\n",
    "    save_to_hdf5_test(data_w_weather, f\"../data/augmented_data/\", f\"tickets_weather_{year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_w_w_ms = process_merge(data_w_weather, ms_data, \"Closest Middle School\", \"Distance to CMS\", \"name\", f\"../data/augmented_data/tickets_w_ms_{year}.h5\")\n",
    "print(data_w_w_ms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_w_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_w_w_ms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_w_w_ms' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms_hs = process_merge(data_w_w_ms, hs_data, \"Closest High School\", \"Distance to CHS\", \"school_name\", f\"../data/augmented_data/tickets_w_ms_hs_{year}.h5\")\n",
    "print(data_w_w_ms_hs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_w_w_ms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m data_w_w_ms\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_w_w_ms' is not defined"
     ]
    }
   ],
   "source": [
    "del data_w_w_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8096326, 53)\n",
      "CPU times: user 43.1 s, sys: 7.08 s, total: 50.2 s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms_hs_li = process_merge(data_w_w_ms_hs, li_data, \"Closest Individual Landmark\", \"Distance to CIL\", \"LPC_NAME\", f\"../data/augmented_data/tickets_w_ms_hs_li_{year}.h5\")\n",
    "print(data_w_w_ms_hs_li.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_w_w_ms_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8096326, 55)\n",
      "CPU times: user 44 s, sys: 7.62 s, total: 51.6 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_w_ms_hs_li_ls = process_merge(data_w_w_ms_hs_li, ls_data, \"Closest Scenic Landmark\", \"Distance to CIS\", \"SCEN_LM_NA\", f\"../data/augmented_data/tickets_w_ms_hs_li_ls_{year}.h5\")\n",
    "print(data_w_w_ms_hs_li_ls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_w_w_ms_hs_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_locations(idx, lat, lang, n):\n",
    "    return [\n",
    "        item.object\n",
    "        for item in list(idx.nearest((lat, lang, lat, lang), n, objects=True))\n",
    "    ]\n",
    "\n",
    "\n",
    "def computational_wrapper(row, lat_i, long_i, idx, time_i, n=1):\n",
    "    locations = pd.DataFrame(get_nearest_locations(idx, row[lat_i], row[long_i], n))\n",
    "    locations = locations[\n",
    "        (locations[\"active_from\"] <= row[time_i])\n",
    "        & (locations[\"active_to\"] >= row[time_i])\n",
    "    ]\n",
    "    if locations.empty:\n",
    "        return computational_wrapper(row, lat_i, long_i, idx, time_i, n * 2)\n",
    "    return (\n",
    "        locations.iloc[0][\"name\"],\n",
    "        locations.iloc[0][\"industry\"],\n",
    "        haversine(\n",
    "            (row[lat_i], row[long_i]),\n",
    "            (locations.iloc[0][\"lat\"], locations.iloc[0][\"long\"]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def process_merge_2(\n",
    "    data, augment_data, new_name, distance_name, name=\"name\", save_location=None\n",
    "):\n",
    "    if os.path.exists(save_location):\n",
    "        return read_hdf5(save_location)\n",
    "    idx = Index()\n",
    "    for i, row in tqdm(enumerate(augment_data.iterrows()), total=augment_data.shape[0]):\n",
    "        row = row[1]\n",
    "        idx.insert(\n",
    "            i,\n",
    "            (row[\"Latitude\"], row[\"Longitude\"], row[\"Latitude\"], row[\"Longitude\"]),\n",
    "            obj={\n",
    "                \"name\": row[name],\n",
    "                \"industry\": row[\"Industry\"],\n",
    "                \"lat\": row[\"Latitude\"],\n",
    "                \"long\": row[\"Longitude\"],\n",
    "                \"active_from\": pd.Timestamp(\n",
    "                    row[\"License Creation Date\"], unit=\"ms\"\n",
    "                ).timestamp()\n",
    "                * 1000,\n",
    "                \"active_to\": pd.Timestamp(\n",
    "                    row[\"License Expiration Date\"], unit=\"ms\"\n",
    "                ).timestamp()\n",
    "                * 1000,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    lat_i = data.columns.tolist().index(\"Latitude\") + 1\n",
    "    long_i = data.columns.tolist().index(\"Longitude\") + 1\n",
    "    time_i = data.columns.tolist().index(\"Issue Date\") + 1\n",
    "    res = []\n",
    "\n",
    "    for row in tqdm(\n",
    "        data.itertuples(), total=data.shape[0], desc=\"Generating reference dataframe\"\n",
    "    ):\n",
    "        res.append(computational_wrapper(row, lat_i, long_i, idx, time_i))\n",
    "\n",
    "    res = pd.DataFrame(\n",
    "        res,\n",
    "        columns=[new_name, \"Industry of CB\", distance_name],\n",
    "        index=data.index,\n",
    "    )\n",
    "\n",
    "    data = data.merge(res, how=\"left\", left_index=True, right_index=True)\n",
    "    file_loc_split = save_location.split(\"/\")\n",
    "    save_to_hdf5(data, \"/\".join(file_loc_split[:-1]), file_loc_split[-1].split(\".\")[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_data = pd.read_csv(\"../data/additional_data/businesses/businesses_NYC_2023_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162222/162222 [00:11<00:00, 13886.64it/s]\n",
      "Generating reference dataframe: 100%|██████████| 8096326/8096326 [2:22:43<00:00, 945.42it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8096326, 58)\n",
      "CPU times: user 2h 39min 43s, sys: 10.5 s, total: 2h 39min 54s\n",
      "Wall time: 2h 39min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_w_ms_hs_li_ls_b= process_merge_2(data_w_w_ms_hs_li_ls, b_data, \"Closest Business\", \"Distance to CB\", \"Business Name\", f\"../data/augmented_data/tickets_w_ms_hs_li_ls_b_{year}.h5\")\n",
    "print(data_w_ms_hs_li_ls_b.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
